apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: istio-rules
spec:
  groups:
  - name: istio-rules
    rules:
    - alert: IstioKubernetesGatewayAvailabilityDrop | istio-ingressgateway-external | PROD
      expr: min(kube_deployment_status_replicas_available{deployment="istio-ingressgateway-external", namespace="istio-system"}) without (instance, pod) < 4
      for: 1m
      labels:
        severity: warning
        channel: slack
        team: devops
      annotations:
        summary: Istio Kubernetes gateway availability drop (instance {{ $labels.instance }})
        description: "Istio External Gateway pods could have dropped. Inbound traffic will likely be affected.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioKubernetesGatewayAvailabilityDropCritical | istio-ingressgateway-external | PROD
      expr: min(kube_deployment_status_replicas_available{deployment="istio-ingressgateway-external", namespace="istio-system"}) without (instance, pod) < 2
      for: 1m
      labels:
        severity: critical
        channel: opsgenie
        team: devops
      annotations:
        summary: Istio Kubernetes gateway availability drop (instance {{ $labels.instance }})
        description: "Istio External Gateway pods could have dropped. Inbound traffic will likely be affected.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioKubernetesGatewayAvailabilityDrop | istio-ingressgateway-internal | PROD
      expr: min(kube_deployment_status_replicas_available{deployment="istio-ingressgateway-internal", namespace="istio-system"}) without (instance, pod) < 2
      for: 1m
      labels:
        severity: critical
        channel: opsgenie
        team: devops
      annotations:
        summary: Istio Kubernetes gateway availability drop (instance {{ $labels.instance }})
        description: "Gateway pods have dropped. Inbound traffic will likely be affected.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioKubernetesGatewayAvailabilityDropCticial | istio-ingressgateway-internal | PROD
      expr: min(kube_deployment_status_replicas_available{deployment="istio-ingressgateway-internal", namespace="istio-system"}) without (instance, pod) < 1
      for: 1m
      labels:
        severity: critical
        channel: opsgenie
        team: devops
      annotations:
        summary: Istio Kubernetes gateway availability drop (instance {{ $labels.instance }})
        description: "Istio Internal Gateway pods counts have dropped to 0. Inbound traffic will be affected.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioHighTotalRequestRate | PROD
      expr: sum(rate(istio_requests_total{reporter="destination"}[5m])) > 7000
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops
      annotations:
        summary: Istio high total request rate (instance {{ $labels.instance }})
        description: "Global request rate in the service mesh is currently high then usual traffic.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioHighTotalRequestRateCritical | PROD
      expr: sum(rate(istio_requests_total{reporter="destination"}[5m])) > 9000
      for: 5m
      labels:
        severity: critical
        channel: opsgenie
        team: devops
      annotations:
        summary: Istio high total request rate (instance {{ $labels.instance }})
        description: "Global request rate in the service mesh is too high in last 5 minutes then usual.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    # - alert: IstioLowTotalRequestRate | PROD
    #   expr: sum(rate(istio_requests_total{reporter="destination"}[5m])) < 100
    #   for: 2m
    #   labels:
    #     severity: high
    #     channel: slack
    #     team: devops
    #   annotations:
    #     summary: Istio low total request rate (instance {{ $labels.instance }})
    #     description: "Global request rate in the service mesh is unusually low.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioHigh5xxErrorRate | PROD
      expr: sum(rate(istio_requests_total{reporter="destination", response_code=~"5.*"}[5m])) / sum(rate(istio_requests_total{reporter="destination"}[2m])) * 100 > 2
      for: 1m
      labels:
        severity: warning
        channel: slack
        team: devops
      annotations:
        summary: Istio high 5xx error rate (instance {{ $labels.instance }})
        description: "High percentage of HTTP 5xx responses in Istio (> 5%).\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: IstioHigh5xxErrorRateCritical | PROD
      expr: sum(rate(istio_requests_total{reporter="destination", response_code=~"5.*"}[5m])) / sum(rate(istio_requests_total{reporter="destination"}[5m])) * 100 > 5
      for: 1m
      labels:
        severity: critical
        channel: opsgenie
        team: devops
      annotations:
        summary: Istio high 5xx error rate (instance {{ $labels.instance }})
        description: "High percentage of HTTP 5xx responses in Istio for last 5 minutes (> 5%).\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    # - alert: IstioHighRequestLatency | PROD
    #   expr: rate(istio_request_duration_milliseconds_sum[1m]) / rate(istio_request_duration_milliseconds_count[1m]) > 0.1
    #   for: 1m
    #   labels:
    #     severity: high
    #     channel: slack
    #     team: devops
    #   annotations:
    #     summary: Istio high request latency (instance {{ $labels.instance }})
    #     description: "Istio average requests execution is longer than 100ms.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    # - alert: IstioLatency99Percentile | PROD
    #   expr: histogram_quantile(0.99, rate(istio_request_duration_milliseconds_bucket[1m])) > 1
    #   for: 1m
    #   labels:
    #     severity: high
    #     channel: slack
    #     team: devops
    #   annotations:
    #     summary: Istio latency 99 percentile (instance {{ $labels.instance }})
    #     description: "Istio 1% slowest resquests are longer than 1s.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    - alert: Istio-503-ErrorRate-High | PROD
      expr: rate(istio_requests_total{response_code=~"503"}[10m]) > 2
      for: 1m
      labels:
        severity: high
        channel: slack
        team: devops
      annotations:
        summary: High 503 errors on request from source_app -> {{ $labels.source_app }} to destination_service_name -> {{ $labels.destination_service_name }} 
        description: "Istio 503 error rate responses in Istio greater than 2. \n  source_app -> {{ $labels.source_app }} and destination_service_name -> {{ $labels.destination_service_name }}."
    - alert: Istio-500-ErrorRate-High | PROD
      expr: rate(istio_requests_total{response_code=~"500"}[10m]) > 5
      for: 1m
      labels:
        severity: high
        channel: slack
        team: devops
      annotations:
        summary: High 500 errors on request from source_app -> {{ $labels.source_app }} to destination_service_name -> {{ $labels.destination_service_name }} 
        description: "Istio 500 error rate responses in Istio greater than 1. \n  source_app -> {{ $labels.source_app }} and destination_service_name -> {{ $labels.destination_service_name }}."    

