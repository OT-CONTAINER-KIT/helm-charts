apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: alertmanager-rules
spec:
  groups:
  - name: alertmanager.rules
    rules:
    - alert: AlertmanagerConfigInconsistent | PROD
      annotations:
        message: |
          The configuration of the instances of the Alertmanager cluster `{{ $labels.namespace }}/{{ $labels.service }}` are out of sync.
          {{ range printf "alertmanager_config_hash{namespace=\"%s\",service=\"%s\"}" $labels.namespace $labels.service | query }}
          Configuration hash for pod {{ .Labels.pod }} is "{{ printf "%.f" .Value }}"
          {{ end }}
        description: |
          The configuration of the instances of the Alertmanager cluster `{{ $labels.namespace }}/{{ $labels.service }}` are out of sync.
          {{ range printf "alertmanager_config_hash{namespace=\"%s\",service=\"%s\"}" $labels.namespace $labels.service | query }}
          Configuration hash for pod {{ .Labels.pod }} is "{{ printf "%.f" .Value }}"
          {{ end }}
      expr: count by(namespace,service) (count_values by(namespace,service) ("config_hash", alertmanager_config_hash{job="kube-alertmanager",namespace="monitoring"})) != 1
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops
    - alert: AlertmanagerFailedReload | PROD
      annotations:
        message: Reloading Alertmanager's configuration has failed for {{ $labels.namespace }}/{{ $labels.pod}}.
        description: Reloading Alertmanager's configuration has failed for {{ $labels.namespace }}/{{ $labels.pod}}.
      expr: alertmanager_config_last_reload_successful{job="kube-alertmanager",namespace="monitoring"} == 0
      for: 10m
      labels:
        severity: warning
        channel: slack
        team: devops
    - alert: AlertmanagerMembersInconsistent | PROD
      annotations:
        message: Alertmanager has not found all other members of the cluster.
        description: Alertmanager has not found all other members of the cluster.
      expr: |-
        alertmanager_cluster_members{job="kube-alertmanager",namespace="monitoring"}
          != on (service) GROUP_LEFT()
        count by (service) (alertmanager_cluster_members{job="kube-alertmanager",namespace="monitoring"})
      for: 5m
      labels:
        severity: warning
        channel: slack
        team: devops
